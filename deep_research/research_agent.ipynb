{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c897bc9",
   "metadata": {},
   "source": [
    "# Deepagent for Research\n",
    "\n",
    "We will use the `deepagents` package to create a research agent. When using the `deepagents` package, it's important to: \n",
    "\n",
    "1. Understand the native tools available\n",
    "2. Supply task-specific tools\n",
    "3. Supply task-specific instructions\n",
    "4. Supply task-specific sub-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14c09e",
   "metadata": {},
   "source": [
    "## Task-Specific Tools \n",
    "\n",
    "You can see an overview of the native tools in the [deepagents package README](https://github.com/langchain-ai/deepagents?tab=readme-ov-file#model) as well as the [quickstarts README](https://github.com/langchain-ai/deepagents-quickstarts). We'll extend this with two task-specific tools. \n",
    "\n",
    "### Search Tool \n",
    "\n",
    "There are different search tools that we can use. For example, we can use [Tavily](https://www.tavily.com/) to search for relevant URLs, then fetches the full webpage content.\n",
    "\n",
    "### Think Tool \n",
    "\n",
    "We'll supply a [think tool](https://www.anthropic.com/engineering/claude-think-tool), which is a useful way to help audit agent decision making. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7632c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_agent.tools import tavily_search, think_tool, contextual_search\n",
    "tools = [tavily_search, think_tool, contextual_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test contextual_search tool\n",
    "print(\"Testing contextual_search tool...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test with a sample query (adjust based on your knowledge base)\n",
    "test_query = \"what is microsofts revenue?\"\n",
    "print(f\"\\nQuery: {test_query}\\n\")\n",
    "\n",
    "try:\n",
    "    result = contextual_search.invoke({\"query\": test_query, \"max_results\": 5})\n",
    "    print(result)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"✅ contextual_search tool is working!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error testing contextual_search: {e}\")\n",
    "    print(\"\\nMake sure you have:\")\n",
    "    print(\"1. CONTEXTUAL_AI_API_KEY set in your .env file\")\n",
    "    print(\"2. CONTEXTUAL_AI_AGENT_ID set in your .env file\")\n",
    "    print(\"3. The 'contextual' package installed: pip install contextual\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd61e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Inspect raw ContextualAI response structure\n",
    "# This helps you understand what data is available\n",
    "import os\n",
    "from contextual import ContextualAI\n",
    "\n",
    "api_key = os.getenv(\"CONTEXTUAL_AI_API_KEY\")\n",
    "agent_id = os.getenv(\"CONTEXTUAL_AI_AGENT_ID\")\n",
    "\n",
    "if api_key and agent_id:\n",
    "    client = ContextualAI(api_key=api_key)\n",
    "    \n",
    "    # Get raw response WITH content text included\n",
    "    query_result = client.agents.query.create(\n",
    "        agent_id=agent_id,\n",
    "        messages=[{\"content\": \"what is microsofts revenue?\", \"role\": \"user\"}],\n",
    "        retrievals_only=True,\n",
    "        include_retrieval_content_text=True  # This is the key parameter!\n",
    "    )\n",
    "    \n",
    "    print(\"Raw QueryResponse structure:\")\n",
    "    print(f\"Conversation ID: {query_result.conversation_id}\")\n",
    "    print(f\"Number of retrieval contents: {len(query_result.retrieval_contents)}\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    # Show first result details\n",
    "    if query_result.retrieval_contents:\n",
    "        first_result = query_result.retrieval_contents[0]\n",
    "        print(\"\\nFirst result structure:\")\n",
    "        print(f\"  - doc_name: {getattr(first_result, 'doc_name', 'N/A')}\")\n",
    "        print(f\"  - content_id: {getattr(first_result, 'content_id', 'N/A')}\")\n",
    "        print(f\"  - doc_id: {getattr(first_result, 'doc_id', 'N/A')}\")\n",
    "        print(f\"  - page: {getattr(first_result, 'page', 'N/A')}\")\n",
    "        print(f\"  - format: {getattr(first_result, 'format', 'N/A')}\")\n",
    "        print(f\"  - score: {getattr(first_result, 'score', 'N/A')}\")\n",
    "        print(f\"  - content_text available: {getattr(first_result, 'content_text', None) is not None}\")\n",
    "        if hasattr(first_result, 'content_text') and first_result.content_text:\n",
    "            print(f\"\\n  - content_text preview (first 300 chars):\")\n",
    "            print(f\"    {first_result.content_text[:300]}...\")\n",
    "        else:\n",
    "            print(f\"\\n  ⚠️  content_text is None or empty\")\n",
    "            print(f\"  Make sure you're using include_retrieval_content_text=True in the query!\")\n",
    "else:\n",
    "    print(\"⚠️  ContextualAI credentials not found. Skipping raw response inspection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3ee5b",
   "metadata": {},
   "source": [
    "## Task-Specific Instructions\n",
    " \n",
    "Next, let's define task specific instructions using [a few prompting techniques for agents](https://youtu.be/XSZP9GhhuAc?si=zowpViL-2j-vI9hA):\n",
    "\n",
    "### 1. Think Like The Agent\n",
    "What instructions would you give a new work colleague?\n",
    "- **Read the question carefully** - What specific information does the user need?\n",
    "- **Start with broader searches** - Use broad, comprehensive queries first\n",
    "- **After each search, pause and assess** - Do I have enough to answer? What's still missing?\n",
    "- **Execute narrower searches as you gather information** - Fill in the gaps.\n",
    "\n",
    "### 2. Concrete Heuristics (Prevent \"Spin-Out\" on excessive tool calls)\n",
    "Use **Hard Limits** to prevent the research agent from calling tools excessively:\n",
    "- **Stop when you can answer confidently** - Don't keep searching for perfection.\n",
    "- **Give it budgets** - Use 2-3 search tool calls for simple queries. Use up to 5 for complex queries.\n",
    "- **Limit** - Always stop after 5 search tool calls if you cannot find the right source(s).\n",
    "\n",
    "### 3. Show your thinking\n",
    "After each search tool calling, use [`think_tool` to analyze the results](https://www.anthropic.com/engineering/claude-think-tool):\n",
    "- What key information did I find? \n",
    "- What's missing?\n",
    "- Do I have enough to answer the question comprehensively?\n",
    "- Should I search more or provide my answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from utils import show_prompt, format_messages\n",
    "from research_agent.prompts import (\n",
    "    RESEARCHER_INSTRUCTIONS,\n",
    "    RESEARCH_WORKFLOW_INSTRUCTIONS,\n",
    "    SUBAGENT_DELEGATION_INSTRUCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb7a89-8a26-4fb4-ba77-b05180f2c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_prompt(RESEARCHER_INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab6e7e",
   "metadata": {},
   "source": [
    "## Task-Specific Sub-Agents\n",
    "\n",
    "You can specify [custom subagents](https://github.com/langchain-ai/deepagents?tab=readme-ov-file#subagents) as a means of context isolation. \n",
    "\n",
    "Here's well define a sub-agent that can search the web for information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6570183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create research sub-agent\n",
    "research_sub_agent = {\n",
    "    \"name\": \"research-agent\",\n",
    "    \"description\": \"Delegate research to the sub-agent researcher. Only give this researcher one topic at a time.\",\n",
    "    \"system_prompt\": RESEARCHER_INSTRUCTIONS.format(date=current_date),\n",
    "    \"tools\": [contextual_search, tavily_search, think_tool],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef99f1d",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Now, we can look at all of our instructions together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limits\n",
    "max_concurrent_research_units = 5\n",
    "max_researcher_iterations = 2\n",
    "\n",
    "# Combine orchestrator instructions (RESEARCHER_INSTRUCTIONS only for sub-agents)\n",
    "INSTRUCTIONS = (\n",
    "    RESEARCH_WORKFLOW_INSTRUCTIONS\n",
    "    + \"\\n\\n\"\n",
    "    + \"=\" * 80\n",
    "    + \"\\n\\n\"\n",
    "    +  SUBAGENT_DELEGATION_INSTRUCTIONS.format(\n",
    "        max_concurrent_research_units=max_concurrent_research_units,\n",
    "        max_researcher_iterations=max_researcher_iterations,\n",
    "    )\n",
    ")\n",
    "\n",
    "show_prompt(INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e3639",
   "metadata": {},
   "source": [
    "### Create the agent\n",
    "\n",
    "Now, we create our deepagent with these components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979ff23-e36a-45b2-bd52-03cf4171f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from deepagents import create_deep_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Model Gemini 3 \n",
    "#model = ChatGoogleGenerativeAI(model=\"gemini-3-pro-preview\")\n",
    "\n",
    "# Model Claude 4.5\n",
    "model = init_chat_model(model=\"anthropic:claude-sonnet-4-5-20250929\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "agent = create_deep_agent(\n",
    "      model=model,\n",
    "      tools=tools, \n",
    "      system_prompt=INSTRUCTIONS,\n",
    "      subagents=[research_sub_agent],\n",
    "  )\n",
    "  \n",
    "# Show the agent\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4296a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query = \"Based on NVIDIA's past performance, what is their best strategy for the future?\"\n",
    "complex_query = '''\n",
    "I need a reality check on NVIDIA's three biggest bets: Automotive, Data Center, and Sovereign AI.\n",
    "For each of these three sectors, can you compare what NVIDIA claims in their official documents (their stated strategy and risks) against what is actually happening in the market right now?\n",
    "I'm specifically looking for a 'Fact vs. Reality' analysis: does recent news and competitor activity (like from AMD or Huawei) validate their internal confidence, or are there cracks in the narrative?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613634c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": complex_query,\n",
    "            }\n",
    "        ],\n",
    "    }, \n",
    ")\n",
    "format_messages(result[\"messages\"])\n",
    "\n",
    "from utils import extract_todos_from_state, format_todos_as_markdown\n",
    "\n",
    "todos = extract_todos_from_state(result)\n",
    "research_question = result[\"messages\"][0].content\n",
    "markdown = format_todos_as_markdown(todos, research_question)\n",
    "print(markdown)\n",
    "\n",
    "# Or read the automatically saved research plan\n",
    "from deepagents.backends.utils import file_data_to_string\n",
    "if '/research_plan.md' in result.get(\"files\", {}):\n",
    "    plan = file_data_to_string(result[\"files\"]['/research_plan.md'])\n",
    "    show_prompt(plan, title=\"Research Plan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents.backends.utils import file_data_to_string\n",
    "\n",
    "# Convert a specific file to string\n",
    "file_content = file_data_to_string(result[\"files\"]['/final_report.md'])\n",
    "show_prompt(file_content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0450c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents.backends.utils import file_data_to_string\n",
    "\n",
    "# Read from agent's in-memory filesystem\n",
    "file_content = file_data_to_string(result[\"files\"]['/final_report.md'])\n",
    "show_prompt(file_content)\n",
    "\n",
    "# Save to disk (add this)\n",
    "with open('final_report.md', 'w') as f:\n",
    "    f.write(file_content)\n",
    "print(\"✅ Saved to: final_report.md\")\n",
    "\n",
    "# Also save research plan if it exists\n",
    "if '/research_plan.md' in result.get(\"files\", {}):\n",
    "    plan_content = file_data_to_string(result[\"files\"]['/research_plan.md'])\n",
    "    with open('research_plan.md', 'w') as f:\n",
    "        f.write(plan_content)\n",
    "    print(\"✅ Saved to: research_plan.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and display sub-agent usage\n",
    "from utils import print_subagent_summary\n",
    "\n",
    "# Print a nice summary\n",
    "print_subagent_summary(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc6784",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "Simple query: https://smith.langchain.com/public/61058724-5b42-4cb2-8d03-0a071a10876d/r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6319e7d",
   "metadata": {},
   "source": [
    "Complex query: https://smith.langchain.com/public/160e15b3-0e18-451b-898e-463d7f1177ef/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
